```{r meta-prelims}
#--------------------------------------------------------------------------------
# Paluck et al. meta-analysis
# Note: I cannot perfectly reproduce their results
#--------------------------------------------------------------------------------
# library(tidyverse)
library(dplyr)
library(metafor)
library(MetaUtility)
library(PublicationBias)

# rounding digits
digits = 2

# helper fn taken from https://osf.io/ue36m/
sim_data2 = function(p,
                     keep.all.studies = FALSE) {
  
  N = p$k * p$per.cluster
  
  # generate cluster random intercepts
  # called "zeta" in paper
  # these are normal even when true effect dist is exponential
  gam1 = rnorm( n = p$k, mean = 0, sd = sqrt( p$V.gam ) )
  gam1i = rep( gam1, each = p$per.cluster )
  
  # generate individual-study random intercepts
  # these are called "gamma" in the paper
  # these are either normal or exponential
  if ( p$true.dist == "norm" ) gam2i = rnorm( n = N, mean = 0, sd = sqrt( p$V - p$V.gam ) )
  
  if ( p$true.dist == "exp" ) {
    true.effect.var = p$V - p$V.gam
    # set var using properties of exponential
    gam2i = rexp( n = N, rate = true.effect.var^(-1/2) )
    # shift to have mean of 0
    # use fact that var = mean^2 in exponential
    gam2i = gam2i - true.effect.var^(1/2)
  }
  
  
  # individual study SEs
  sei = runif( n = N, min = p$sei.min, max = p$sei.max )
  
  # individual study means
  if ( p$SE.corr == TRUE ) {
    beta = 6
    mui = p$mu + beta * sei + gam1i + gam2i
    
    # recenter them to have desired mean of p$mu
    # because E[sei}]
    mui = mui - beta * mean(sei)
    
    cor(sei, mui)
  } else {
    mui = p$mu + gam1i + gam2i
  }
  
  # individual study point estimates
  yi = rnorm( n = N, mean = mui, sd = sei )
  
  # NEW: make cluster variable
  # this way, if we generate (say) 5 studies per "cluster", but V.gam = 0 in order
  #  to effectively generate without clustering, the cluster variable we ultimately
  #  pass to robumeta correctly reflects the lack of clustering
  if ( p$V.gam == 0 ) cluster = 1:N else cluster = rep(1:p$k, each = p$per.cluster)
  
  # suppress warnings from cor if SD of mui is 0 (fixed-effects model)
  d = suppressWarnings( data.frame( cluster = cluster,
                                    Study.name = 1:N,
                                    mui,
                                    yi = yi,
                                    sei = sei,
                                    vi = sei^2,
                                    pval = 2 * ( 1 - pnorm( abs(yi) / sei ) ),
                                    SE.corr.emp = cor(sei, mui) ) )  # empirical correlation
  
  # 1-tailed publication bias
  signif = d$pval < 0.05 & d$yi > 0
  publish = rep( 1, nrow(d) )
  publish[ signif == FALSE ] = rbinom( n = sum(signif == FALSE), size = 1, prob = 1/p$eta )
  
  d$weight = 1
  d$weight[ signif == 0 ] = p$eta
  
  # optionally, also select for small SE
  # Fi as defined in Supplement
  # tertiles of empirical SEs prior to selection
  Fi = rep( 1, nrow(d) )  # so that it has no effect if we're not selecting based on SE
  if ( p$select.SE == TRUE ) {
    terts = p$sei.min + (p$sei.max - p$sei.min) * c(1/3, 2/3)
    # prob of inclusion based on SE
    P.Fi = rep(NA, nrow(d))
    P.Fi[ d$sei < terts[1] ] = 1
    #Fi[ d$sei >= terts[1] ] = 0
    P.Fi[ d$sei >= terts[1] & d$sei < terts[2] ] = .75
    P.Fi[ d$sei >= terts[2] ] = .5
    Fi = rbinom( n = nrow(d),
                 size = 1,
                 prob = P.Fi )
  }
  
  if ( keep.all.studies == FALSE ) d = d[ publish == 1 & Fi == 1, ]
  if ( keep.all.studies == TRUE ){
    # just add the indicators
    d$publish = publish
    d$Fi = Fi
  }
  
  # record the mean empirical SE (after publication bias) as sanity check on SE selection
  # but avoid errors if d now has 0 studies
  if ( nrow(d) > 0 ) {
    d$SE.mean.emp = mean(d$sei)
    d$P.select.SE.emp = mean(Fi)
    d$P.publish.emp = mean(publish)
    return(d)
  } else {
    # still return the empty dataset for use in doParallel
    return(d)
  }
}



DF <- read.csv(here::here("data","Contact_quant_outcomes.csv"))


# remove supplemental studies (see Paluck et al. Supplement Section 1)
DF <- DF[1:27, ]

# calculate total n and determine whether d estimate was significant
DF <- DF %>% 
  
  rowwise() %>% 
  
  # calculate total n
  mutate(n_total = n_t + n_c) %>% 
  
  # determine whether d estimate was significant
  ## calculate lower and upper bounds
  mutate(lb = d - (1.96 * sqrt(var_d)),
         ub = d + (1.96 * sqrt(var_d))) %>% 
  
  ## determine significance
  mutate(sig = if_else(
    condition = lb > 0,
    true = 1,
    false = 0)) %>% 
  
  ungroup() %>% 
  
  # MM likes it ordered by variance for forest plot prettiness
  arrange(var_d)

# fixed effect meta
fe.m <- rma(yi = d,
            vi = var_d,
            data = DF,
            method = "FE")

# random effect meta
re.m <- rma(yi = d,
            vi = var_d,
            data = DF,
            method = "REML",
            knha = TRUE,
            # for forest plot joy:
            slab = DF$name_short)

# estimated heterogeneity with inference
t2.CI = tau_CI(meta = re.m)
tauStats = round( c( sqrt(re.m$tau2), t2.CI[1], t2.CI[2] ), digits )

```